{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# ğŸ¤ Spark-TTS on Google Colab\n",
        "\n",
        "This notebook allows you to run Spark-TTS (Text-to-Speech with Voice Cloning) on Google Colab.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/Spark-TTS/blob/main/Spark_TTS_Colab.ipynb)\n",
        "\n",
        "## Features:\n",
        "- ğŸ¯ **Voice Cloning**: Clone any voice from a reference audio\n",
        "- ğŸ¨ **Voice Creation**: Generate synthetic voices with custom parameters\n",
        "- ğŸš€ **GPU Acceleration**: Utilizes Colab's free GPU for faster inference\n",
        "- ğŸŒ **Public Access**: Share your TTS interface with others\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## ğŸ“‹ Setup Instructions\n",
        "\n",
        "1. **Enable GPU**: Go to `Runtime` > `Change runtime type` > Select `GPU` as Hardware accelerator\n",
        "2. **Run the cells below** in order\n",
        "3. **Upload your model** when prompted\n",
        "4. **Access the web interface** via the generated link\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "check_gpu",
        "outputId": "98825243-57c4-414a-d606-fe79b0fdad5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” System Information:\n",
            "Python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "ğŸ”¥ GPU: Tesla T4\n",
            "GPU Memory: 14.7 GB\n"
          ]
        }
      ],
      "source": [
        "#@title ğŸ”§ Check GPU Availability\n",
        "\n",
        "import torch\n",
        "import os\n",
        "\n",
        "print(\"ğŸ” System Information:\")\n",
        "print(f\"Python version: {os.sys.version}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"ğŸ”¥ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "else:\n",
        "    print(\"âš ï¸ GPU not available. Consider enabling GPU in Runtime settings.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "install_dependencies",
        "outputId": "ebd965e8-0ac8-4699-f93b-e84ae0a16f04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ Installing required packages...\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ… Dependencies installed successfully!\n"
          ]
        }
      ],
      "source": [
        "#@title ğŸ“¦ Install Dependencies\n",
        "\n",
        "print(\"ğŸ“¦ Installing required packages...\")\n",
        "\n",
        "# Install core packages\n",
        "!pip install -q gradio soundfile torch torchaudio transformers\n",
        "\n",
        "# Install additional dependencies\n",
        "!pip install -q librosa numpy scipy\n",
        "\n",
        "print(\"âœ… Dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "clone_repo",
        "outputId": "3d874a96-403f-40d7-9ec7-1967843b826b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ Cloning Spark-TTS repository...\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "Cloning into '/content/Spark-TTS'...\n",
            "fatal: Unable to read current working directory: No such file or directory\n",
            "âœ… Repository cloned successfully!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Spark-TTS'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2272761661.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Change to the project directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Spark-TTS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ğŸ“‚ Current directory: {os.getcwd()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Spark-TTS'"
          ]
        }
      ],
      "source": [
        "#@title ğŸ“¥ Clone Spark-TTS Repository\n",
        "\n",
        "import os\n",
        "\n",
        "# Clone the repository\n",
        "if not os.path.exists('/content/Spark-TTS'):\n",
        "    print(\"ğŸ“¥ Cloning Spark-TTS repository...\")\n",
        "    !git clone https://github.com/deluxebear/Spark-TTS.git /content/Spark-TTS\n",
        "    print(\"âœ… Repository cloned successfully!\")\n",
        "else:\n",
        "    print(\"ğŸ“ Repository already exists, updating...\")\n",
        "    !cd /content/Spark-TTS && git pull\n",
        "    print(\"âœ… Repository updated!\")\n",
        "\n",
        "# Change to the project directory\n",
        "os.chdir('/content/Spark-TTS')\n",
        "print(f\"ğŸ“‚ Current directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_model",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ¤– Download Pre-trained Model\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "model_dir = \"/content/Spark-TTS/pretrained_models/Spark-TTS-0.5B\"\n",
        "\n",
        "# Create model directory\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "os.makedirs(\"/content/example/results\", exist_ok=True)\n",
        "\n",
        "print(\"ğŸ¤– Model Setup Options:\")\n",
        "print(\"1. Auto-download (if URL available)\")\n",
        "print(\"2. Manual upload\")\n",
        "print()\n",
        "\n",
        "# Check if model already exists\n",
        "if os.path.exists(f\"{model_dir}/config.json\"):\n",
        "    print(\"âœ… Model already exists!\")\n",
        "else:\n",
        "    print(\"ğŸ“¥ Model not found. Please upload your model files.\")\n",
        "    print(f\"ğŸ“ Upload your model files to: {model_dir}\")\n",
        "    print(\"Required files: config.json, pytorch_model.bin, tokenizer files, etc.\")\n",
        "    print()\n",
        "    print(\"ğŸ’¡ Tip: You can upload files using the file browser on the left panel\")\n",
        "\n",
        "    # Option to upload files\n",
        "    upload_choice = input(\"\\nDo you want to upload files now? (y/n): \")\n",
        "    if upload_choice.lower() == 'y':\n",
        "        print(\"ğŸ“¤ Please select your model files:\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        # Move uploaded files to model directory\n",
        "        for filename, content in uploaded.items():\n",
        "            with open(f\"{model_dir}/{filename}\", 'wb') as f:\n",
        "                f.write(content)\n",
        "            print(f\"âœ… Uploaded: {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_webui",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ğŸŒ Create and Launch WebUI\n",
        "\n",
        "# Create the Colab-optimized webui file\n",
        "webui_code = '''\n",
        "import os\n",
        "import torch\n",
        "import soundfile as sf\n",
        "import logging\n",
        "import gradio as gr\n",
        "import platform\n",
        "from datetime import datetime\n",
        "from cli.SparkTTS import SparkTTS\n",
        "from sparktts.utils.token_parser import LEVELS_MAP_UI\n",
        "\n",
        "# Colab detection\n",
        "IN_COLAB = True\n",
        "\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda:0\")\n",
        "        print(f\"ğŸ”¥ Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"âš ï¸ GPU not available, using CPU\")\n",
        "    return device\n",
        "\n",
        "def initialize_model(model_dir=\"pretrained_models/Spark-TTS-0.5B\"):\n",
        "    print(f\"ğŸ“‚ Loading model from: {model_dir}\")\n",
        "    device = get_device()\n",
        "    model = SparkTTS(model_dir, device)\n",
        "    return model\n",
        "\n",
        "def run_tts(text, model, prompt_text=None, prompt_speech=None,\n",
        "           gender=None, pitch=None, speed=None, save_dir=\"/content/example/results\"):\n",
        "    if prompt_text is not None:\n",
        "        prompt_text = None if len(prompt_text) <= 1 else prompt_text\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "    save_path = os.path.join(save_dir, f\"{timestamp}.wav\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        wav = model.inference(text, prompt_speech, prompt_text, gender, pitch, speed)\n",
        "        sf.write(save_path, wav, samplerate=16000)\n",
        "\n",
        "    return save_path\n",
        "\n",
        "# Initialize model\n",
        "try:\n",
        "    model = initialize_model()\n",
        "    print(\"âœ… Model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to load model: {e}\")\n",
        "    model = None\n",
        "\n",
        "def voice_clone(text, prompt_text, prompt_wav_upload, prompt_wav_record):\n",
        "    if not text.strip():\n",
        "        return None, \"Please enter text to synthesize\"\n",
        "    if model is None:\n",
        "        return None, \"Model not loaded\"\n",
        "\n",
        "    prompt_speech = prompt_wav_upload if prompt_wav_upload else prompt_wav_record\n",
        "    prompt_text_clean = None if len(prompt_text) < 2 else prompt_text\n",
        "\n",
        "    try:\n",
        "        audio_path = run_tts(text, model, prompt_text_clean, prompt_speech)\n",
        "        return audio_path, \"âœ… Audio generated successfully!\"\n",
        "    except Exception as e:\n",
        "        return None, f\"âŒ Error: {str(e)}\"\n",
        "\n",
        "def voice_creation(text, gender, pitch, speed):\n",
        "    if not text.strip():\n",
        "        return None, \"Please enter text to synthesize\"\n",
        "    if model is None:\n",
        "        return None, \"Model not loaded\"\n",
        "\n",
        "    try:\n",
        "        pitch_val = LEVELS_MAP_UI[int(pitch)]\n",
        "        speed_val = LEVELS_MAP_UI[int(speed)]\n",
        "        audio_path = run_tts(text, model, gender=gender, pitch=pitch_val, speed=speed_val)\n",
        "        return audio_path, \"âœ… Audio generated successfully!\"\n",
        "    except Exception as e:\n",
        "        return None, f\"âŒ Error: {str(e)}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks(title=\"Spark-TTS Colab\") as demo:\n",
        "    gr.HTML(\"\"\"\n",
        "    <div style=\"text-align: center; margin-bottom: 20px;\">\n",
        "        <h1>ğŸ¤ Spark-TTS on Google Colab</h1>\n",
        "        <p>High-quality Text-to-Speech synthesis with voice cloning</p>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"ğŸ¯ Voice Clone\"):\n",
        "            with gr.Row():\n",
        "                prompt_wav_upload = gr.Audio(sources=[\"upload\"], type=\"filepath\",\n",
        "                                           label=\"ğŸ“ Upload Reference Audio\")\n",
        "                prompt_wav_record = gr.Audio(sources=[\"microphone\"], type=\"filepath\",\n",
        "                                           label=\"ğŸ™ï¸ Record Reference Audio\")\n",
        "\n",
        "            with gr.Row():\n",
        "                text_input = gr.Textbox(label=\"ğŸ“ Text to Synthesize\", lines=3,\n",
        "                                      value=\"Hello, this is a test of voice cloning.\")\n",
        "                prompt_text_input = gr.Textbox(label=\"ğŸ“„ Reference Text (Optional)\", lines=3)\n",
        "\n",
        "            generate_btn = gr.Button(\"ğŸš€ Generate Speech\", variant=\"primary\")\n",
        "\n",
        "            with gr.Row():\n",
        "                audio_output = gr.Audio(label=\"ğŸ”Š Generated Audio\")\n",
        "                status_output = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "            generate_btn.click(voice_clone,\n",
        "                             inputs=[text_input, prompt_text_input, prompt_wav_upload, prompt_wav_record],\n",
        "                             outputs=[audio_output, status_output])\n",
        "\n",
        "        with gr.TabItem(\"ğŸ¨ Voice Creation\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    gender = gr.Radio([\"male\", \"female\"], value=\"male\", label=\"ğŸ‘¤ Gender\")\n",
        "                    pitch = gr.Slider(1, 5, value=3, step=1, label=\"ğŸµ Pitch\")\n",
        "                    speed = gr.Slider(1, 5, value=3, step=1, label=\"âš¡ Speed\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    text_creation = gr.Textbox(label=\"ğŸ“ Input Text\", lines=4,\n",
        "                                             value=\"You can customize voice parameters.\")\n",
        "                    create_btn = gr.Button(\"ğŸ¯ Create Voice\", variant=\"primary\")\n",
        "\n",
        "            with gr.Row():\n",
        "                audio_creation = gr.Audio(label=\"ğŸ”Š Generated Audio\")\n",
        "                status_creation = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "            create_btn.click(voice_creation,\n",
        "                           inputs=[text_creation, gender, pitch, speed],\n",
        "                           outputs=[audio_creation, status_creation])\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch(share=True, server_name=\"0.0.0.0\", server_port=7860, show_error=True)\n",
        "'''\n",
        "\n",
        "# Write the webui code to a file\n",
        "with open('/content/Spark-TTS/webui_colab.py', 'w') as f:\n",
        "    f.write(webui_code)\n",
        "\n",
        "print(\"âœ… WebUI code created successfully!\")\n",
        "print(\"ğŸš€ Launching Spark-TTS WebUI...\")\n",
        "print(\"â³ This may take a few moments...\")\n",
        "\n",
        "# Run the webui\n",
        "exec(open('/content/Spark-TTS/webui_colab.py').read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usage_tips"
      },
      "source": [
        "## ğŸ’¡ Usage Tips\n",
        "\n",
        "### Voice Cloning:\n",
        "1. **Upload a reference audio** (WAV, MP3) with clear speech\n",
        "2. **Enter the text** you want to synthesize\n",
        "3. **Optionally provide reference text** for better results\n",
        "4. Click **Generate Speech**\n",
        "\n",
        "### Voice Creation:\n",
        "1. **Select gender** (male/female)\n",
        "2. **Adjust pitch and speed** (1=lowest, 5=highest)\n",
        "3. **Enter your text**\n",
        "4. Click **Create Voice**\n",
        "\n",
        "### Tips:\n",
        "- ğŸ“ **Reference audio**: Use clear, noise-free audio for best results\n",
        "- â±ï¸ **Length**: 3-30 seconds of reference audio works best\n",
        "- ğŸ§ **Quality**: Higher quality reference audio = better cloned voice\n",
        "- ğŸ’¾ **Download**: Right-click on generated audio to save\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_results",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ’¾ Download Generated Audio Files\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "results_dir = \"/content/example/results\"\n",
        "\n",
        "if os.path.exists(results_dir) and os.listdir(results_dir):\n",
        "    print(\"ğŸ“ Found generated audio files:\")\n",
        "    audio_files = [f for f in os.listdir(results_dir) if f.endswith('.wav')]\n",
        "\n",
        "    for i, file in enumerate(audio_files, 1):\n",
        "        print(f\"{i}. {file}\")\n",
        "\n",
        "    if len(audio_files) == 1:\n",
        "        # Download single file\n",
        "        file_path = os.path.join(results_dir, audio_files[0])\n",
        "        files.download(file_path)\n",
        "        print(f\"âœ… Downloaded: {audio_files[0]}\")\n",
        "    else:\n",
        "        # Create zip file for multiple files\n",
        "        zip_path = \"/content/generated_audio.zip\"\n",
        "        with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "            for file in audio_files:\n",
        "                file_path = os.path.join(results_dir, file)\n",
        "                zipf.write(file_path, file)\n",
        "\n",
        "        files.download(zip_path)\n",
        "        print(f\"âœ… Downloaded zip file with {len(audio_files)} audio files\")\n",
        "else:\n",
        "    print(\"âŒ No generated audio files found.\")\n",
        "    print(\"ğŸ’¡ Generate some audio using the interface above first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "troubleshooting"
      },
      "source": [
        "## ğŸ”§ Troubleshooting\n",
        "\n",
        "### Common Issues:\n",
        "\n",
        "1. **Model loading errors**:\n",
        "   - Ensure all model files are uploaded correctly\n",
        "   - Check that the model directory structure is correct\n",
        "\n",
        "2. **GPU memory issues**:\n",
        "   - Restart runtime: `Runtime` > `Restart runtime`\n",
        "   - Use shorter text inputs\n",
        "\n",
        "3. **Interface not loading**:\n",
        "   - Wait for the model to load completely\n",
        "   - Check the console for error messages\n",
        "\n",
        "4. **Audio quality issues**:\n",
        "   - Use high-quality reference audio (16kHz+)\n",
        "   - Ensure reference audio is clear and noise-free\n",
        "\n",
        "### Need Help?\n",
        "- ğŸ“– Check the [Spark-TTS documentation](https://github.com/SparkAudio/Spark-TTS)\n",
        "- ğŸ› Report issues on [GitHub](https://github.com/SparkAudio/Spark-TTS/issues)\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“„ License\n",
        "This project is licensed under the Apache License 2.0. See the LICENSE file for details.\n",
        "\n",
        "### ğŸ™ Credits\n",
        "- **Spark-TTS** by SparkAudio\n",
        "- **Gradio** for the web interface\n",
        "- **Google Colab** for free GPU access\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}